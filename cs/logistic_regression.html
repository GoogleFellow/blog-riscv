<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>逻辑回归 | suda-morris 个人博客</title>
    <meta name="description" content="记录学习生活，探索未知领域">
    <link rel="icon" href="/blog/favicon.png">
  <link rel="manifest" href="/blog/manifest.json">
    
    <link rel="preload" href="/blog/assets/css/0.styles.aea52b3d.css" as="style"><link rel="preload" href="/blog/assets/js/app.63bb8dec.js" as="script"><link rel="preload" href="/blog/assets/js/2.4a73e09d.js" as="script"><link rel="preload" href="/blog/assets/js/11.72cb3854.js" as="script"><link rel="preload" href="/blog/assets/js/3.b11672f7.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.b0c0010d.js"><link rel="prefetch" href="/blog/assets/js/12.1ad341e6.js"><link rel="prefetch" href="/blog/assets/js/13.475ed0f9.js"><link rel="prefetch" href="/blog/assets/js/14.509a879e.js"><link rel="prefetch" href="/blog/assets/js/15.6ab69359.js"><link rel="prefetch" href="/blog/assets/js/16.0bf9f453.js"><link rel="prefetch" href="/blog/assets/js/17.632e3b2c.js"><link rel="prefetch" href="/blog/assets/js/18.cbaa8241.js"><link rel="prefetch" href="/blog/assets/js/19.055b1066.js"><link rel="prefetch" href="/blog/assets/js/20.3b4797b4.js"><link rel="prefetch" href="/blog/assets/js/21.05bb93e6.js"><link rel="prefetch" href="/blog/assets/js/22.93b038ed.js"><link rel="prefetch" href="/blog/assets/js/23.dda8ebb0.js"><link rel="prefetch" href="/blog/assets/js/24.e1e5cf40.js"><link rel="prefetch" href="/blog/assets/js/25.149e7db6.js"><link rel="prefetch" href="/blog/assets/js/26.c3f5eed4.js"><link rel="prefetch" href="/blog/assets/js/27.5d3cbe94.js"><link rel="prefetch" href="/blog/assets/js/28.7bf133b4.js"><link rel="prefetch" href="/blog/assets/js/29.7c9a47b8.js"><link rel="prefetch" href="/blog/assets/js/30.6e7d5b7a.js"><link rel="prefetch" href="/blog/assets/js/31.b1fabd67.js"><link rel="prefetch" href="/blog/assets/js/32.9decea62.js"><link rel="prefetch" href="/blog/assets/js/33.fa4e1467.js"><link rel="prefetch" href="/blog/assets/js/34.11becf88.js"><link rel="prefetch" href="/blog/assets/js/35.dcce5440.js"><link rel="prefetch" href="/blog/assets/js/36.5ae704cf.js"><link rel="prefetch" href="/blog/assets/js/37.d828fcd3.js"><link rel="prefetch" href="/blog/assets/js/38.4312e88b.js"><link rel="prefetch" href="/blog/assets/js/39.094559c3.js"><link rel="prefetch" href="/blog/assets/js/4.e3e090f7.js"><link rel="prefetch" href="/blog/assets/js/40.0ca172e6.js"><link rel="prefetch" href="/blog/assets/js/41.e0ca6b7b.js"><link rel="prefetch" href="/blog/assets/js/42.d8d152e7.js"><link rel="prefetch" href="/blog/assets/js/43.c3053021.js"><link rel="prefetch" href="/blog/assets/js/44.30cf0529.js"><link rel="prefetch" href="/blog/assets/js/45.3f4b474c.js"><link rel="prefetch" href="/blog/assets/js/46.547cb6b8.js"><link rel="prefetch" href="/blog/assets/js/47.778b8037.js"><link rel="prefetch" href="/blog/assets/js/48.2ee0be6e.js"><link rel="prefetch" href="/blog/assets/js/49.aac13fd5.js"><link rel="prefetch" href="/blog/assets/js/5.2a354d3d.js"><link rel="prefetch" href="/blog/assets/js/50.07abbf60.js"><link rel="prefetch" href="/blog/assets/js/51.1bd8fe4f.js"><link rel="prefetch" href="/blog/assets/js/52.bfc474a5.js"><link rel="prefetch" href="/blog/assets/js/53.442d5e52.js"><link rel="prefetch" href="/blog/assets/js/54.b8a3d93b.js"><link rel="prefetch" href="/blog/assets/js/55.4c75e5cd.js"><link rel="prefetch" href="/blog/assets/js/56.d9d573dc.js"><link rel="prefetch" href="/blog/assets/js/57.8f3b4900.js"><link rel="prefetch" href="/blog/assets/js/58.cfa6a4a1.js"><link rel="prefetch" href="/blog/assets/js/59.e91c2df4.js"><link rel="prefetch" href="/blog/assets/js/6.a0364a73.js"><link rel="prefetch" href="/blog/assets/js/60.80dc3e63.js"><link rel="prefetch" href="/blog/assets/js/61.bc8d93c4.js"><link rel="prefetch" href="/blog/assets/js/62.e21299a6.js"><link rel="prefetch" href="/blog/assets/js/63.0b14764d.js"><link rel="prefetch" href="/blog/assets/js/64.c88d5184.js"><link rel="prefetch" href="/blog/assets/js/65.0e8fed7b.js"><link rel="prefetch" href="/blog/assets/js/66.631e6987.js"><link rel="prefetch" href="/blog/assets/js/67.deda1286.js"><link rel="prefetch" href="/blog/assets/js/68.d488748b.js"><link rel="prefetch" href="/blog/assets/js/69.4084b8dc.js"><link rel="prefetch" href="/blog/assets/js/7.05f8ac37.js"><link rel="prefetch" href="/blog/assets/js/70.13a5a6d3.js"><link rel="prefetch" href="/blog/assets/js/71.75c2f594.js"><link rel="prefetch" href="/blog/assets/js/8.ab17c590.js"><link rel="prefetch" href="/blog/assets/js/9.5709aa1f.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.aea52b3d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><!----> <span class="site-name">suda-morris 个人博客</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">Home</a></div><div class="nav-item"><a href="/blog/cs/" class="nav-link router-link-active">CS</a></div><div class="nav-item"><a href="/blog/ee/" class="nav-link">EE</a></div><div class="nav-item"><a href="/blog/others/" class="nav-link">Others</a></div> <a href="https://github.com/suda-morris/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">Home</a></div><div class="nav-item"><a href="/blog/cs/" class="nav-link router-link-active">CS</a></div><div class="nav-item"><a href="/blog/ee/" class="nav-link">EE</a></div><div class="nav-item"><a href="/blog/others/" class="nav-link">Others</a></div> <a href="https://github.com/suda-morris/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><a href="/blog/cs/about.html" class="sidebar-link">关于本栏目</a></li><li><a href="/blog/cs/bash.html" class="sidebar-link">bash 基本语法</a></li><li><a href="/blog/cs/compilation.html" class="sidebar-link">编译</a></li><li><a href="/blog/cs/logistic_regression.html" class="active sidebar-link">逻辑回归</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/cs/logistic_regression.html#数学公式推导" class="sidebar-link">数学公式推导</a></li><li class="sidebar-sub-header"><a href="/blog/cs/logistic_regression.html#python程序编写" class="sidebar-link">Python程序编写</a></li></ul></li></ul> </aside> <main class="page"> <div class="content default"><h1 id="逻辑回归"><a href="#逻辑回归" aria-hidden="true" class="header-anchor">#</a> 逻辑回归</h1> <blockquote><ol><li>Logistic回归虽然是名字中带有“回归”，但实际上它是一种<strong>分类算法</strong>，主要应用与<strong>二分类</strong>问题(输出只有两种结果，比如0和1)</li> <li>逻辑回归实质上可以看作是一种简单的<strong>神经网络</strong></li></ol></blockquote> <p><img src="/blog/images/cs/ai/logistic_regression.png" alt="logistic_regression"></p> <h2 id="数学公式推导"><a href="#数学公式推导" aria-hidden="true" class="header-anchor">#</a> 数学公式推导</h2> <p>假设神经元的突触的权重向量为<strong>w</strong>，线性偏置为<strong>b</strong>(标量)，对于第i个样本$x^{(i)}$来说：</p> <p>$$z^{(i)} = w^T x^{(i)} + b\tag{1}$$</p> <p>得到的$z^{(i)}$需要进一步输入激活函数，激活函数的选择有很多种，考虑到Logistic回归的输出只有0和1两种情况，因此选用sigmoid函数会比较符合要求：</p> <p>$$\hat{y}^{(i)}=a^{(i)}=sigmoid(z^{(i)})\tag{2}$$</p> <p>sigmoid函数的导数：</p> <p>$$\frac{da}{dz}=a(1-a)\tag{3}$$</p> <p><img src="/blog/images/cs/ai/sigmoid_function.png" alt="sigmoid_function"></p> <p>如何衡量预测结果的好坏，需要定义损失函数<strong>L</strong>：</p> <p>$$ L(a^{(i)},y^{(i)})=- y^{(i)}\ln(a^{(i)})-(1-y^{(i)})\ln(1-a^{(i)})\tag{4}$$</p> <p>那么价值函数<strong>J</strong>就是所有样本的损失值的平均：</p> <p>$$ J=\frac{1}{m}\sum_{i=1}^mL(a^{(i)}, y^{(i)})\tag{5}$$</p> <p>我们的目标是通过多次的迭代，求得使得<strong>J</strong>最小的自变量参数w和b，这里使用的优化算法为梯度下降法，其中α称为学习率，是0~1之间的浮点数：</p> <p>$$\theta=\theta-\alpha d\theta\tag{6}$$</p> <p>我们把求解价值函数的过程称为<strong>正向传播</strong>，把求解梯度的过程称为<strong>反向传播</strong></p> <p>价值函数对于第j个突触$w_j$的梯度：
$$
\frac{\partial J}{\partial w_j}=\frac{1}{m}\sum_{i=1}^m\frac{\partial}{\partial w_j}[-y^{(i)}\ln{(a^{(i)})}-(1-y^{(i)})\ln{(1-a^{(i)})}]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{-y^{(i)}}{a^{(i)}}\cdot\frac{\partial{a^{(i)}}}{\partial{w_j}}+\frac{(1-y^{i})}{1-a^{(i)}}\cdot\frac{\partial{a^{i}}}{\partial{w_j}}]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{\partial{a^{(i)}}}{\partial{w_j}}\cdot(\frac{1-y^{(i)}}{1-a^{(i)}}-\frac{y^{(i)}}{a^{(i)}})]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{d{a^{(i)}}}{d{z^{(i)}}}\cdot\frac{\partial{z^{(i)}}}{\partial{w_j}}\cdot(\frac{1-y^{(i)}}{1-a^{(i)}}-\frac{y^{(i)}}{a^{(i)}})]\
=\frac{1}{m}\sum_{i=1}^{m}[a^{(i)}\cdot(1-a^{(i)})\cdot x_j^{(i)}\cdot\frac{a^{(i)}-y^{(i)}}{a^{(i)}\cdot(1-a^{(i)})}]\
=\frac{1}{m}\sum_{i=1}^{m}[x_j^{(i)}\cdot(a^{(i)}-y^{(i)})]
$$
价值函数<strong>J</strong>对于所有突触的权重向量<strong>w</strong>的梯度：</p> <p>$$ \frac{\partial J}{\partial w}=\frac{1}{m}X(A-Y)^T\tag{7}$$</p> <p>价值函数<strong>J</strong>对偏置<strong>b</strong>的梯度：</p> <p>$$ \frac{\partial J}{\partial b}=\frac{1}{m}\sum_{i=1}^m (a^{(i)}-y^{(i)})\tag{8}$$</p> <p>所以，每一次迭代的过程中，对w和b的<strong>更新规则</strong>为：</p> <p>$$w:=w-\alpha\frac{\partial{J}}{\partial{w}}\tag{9}$$</p> <p>$$b:=b-\alpha\frac{\partial{J}}{\partial{b}}\tag{10}$$</p> <h2 id="python程序编写"><a href="#python程序编写" aria-hidden="true" class="header-anchor">#</a> Python程序编写</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd


<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Compute the sigmoid of z
    :param z: A scalar or numpy array of any size.
    :return: sigmoid(z)
    &quot;&quot;&quot;</span>
    s <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> s


<span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_iterations<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Builds the logistic regression model
        :param num_iterations: hyperparameter representing the number of iterations to optimize the parameters
        :param learning_rate: hyperparameter representing the learning rate when update the parameters
        :param print_cost: Set to true to print the cost every 100 iterations
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>n_iter <span class="token operator">=</span> num_iterations
        self<span class="token punctuation">.</span>learn_rate <span class="token operator">=</span> learning_rate
        self<span class="token punctuation">.</span>print_cost <span class="token operator">=</span> print_cost
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># weights, a numpy array of size</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># bias, a scalar</span>

    <span class="token keyword">def</span> <span class="token function">__initialize_with_zeros</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.
        :param dim: size of the w vector we want
        :return: w -- initialized vector of shape (dim, 1); b -- initialized scalar (corresponds to the bias)
        &quot;&quot;&quot;</span>
        w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>w<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> w<span class="token punctuation">,</span> b

    <span class="token keyword">def</span> <span class="token function">__propagate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Implement the cost function and its gradient for the propagation
        :param X: input data
        :param Y: label vector
        :return: grads --- results of backward propagation; cost --- results of forward propagation
        &quot;&quot;&quot;</span>
        m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment"># FORWARD PROPAGATION (FROM X TO COST)</span>
        Z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        A <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>  <span class="token comment"># compute activation</span>
        cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> A<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># compute cost</span>

        <span class="token comment"># BACKWARD PROPAGATION (TO FIND GRAD)</span>
        dw <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>A <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># gradient of the loss with respect to w, thus same shape as w</span>
        db <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>A <span class="token operator">-</span> Y<span class="token punctuation">)</span> <span class="token operator">/</span> m  <span class="token comment"># gradient of the loss with respect to b, thus same shape as b</span>

        <span class="token keyword">assert</span> <span class="token punctuation">(</span>dw<span class="token punctuation">.</span>shape <span class="token operator">==</span> self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>db<span class="token punctuation">.</span>dtype <span class="token operator">==</span> <span class="token builtin">float</span><span class="token punctuation">)</span>
        cost <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>cost<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;dw&quot;</span><span class="token punctuation">:</span> dw<span class="token punctuation">,</span>
                 <span class="token string">&quot;db&quot;</span><span class="token punctuation">:</span> db<span class="token punctuation">}</span>
        <span class="token keyword">return</span> grads<span class="token punctuation">,</span> cost

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        This function optimizes w and b by running a gradient descent algorithm
        :param X_train: input data
        :param Y_train: label vector
        :return: costs -- list of all the costs computed during the optimization
        &quot;&quot;&quot;</span>
        <span class="token comment"># initialize parameters with zeros</span>
        self<span class="token punctuation">.</span>w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>b <span class="token operator">=</span> self<span class="token punctuation">.</span>__initialize_with_zeros<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            grads<span class="token punctuation">,</span> cost <span class="token operator">=</span> self<span class="token punctuation">.</span>__propagate<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>  <span class="token comment"># Cost and gradient calculation</span>
            dw <span class="token operator">=</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dw&quot;</span><span class="token punctuation">]</span>
            db <span class="token operator">=</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span><span class="token punctuation">]</span>
            <span class="token comment"># update rule</span>
            self<span class="token punctuation">.</span>w <span class="token operator">-=</span> self<span class="token punctuation">.</span>learn_rate <span class="token operator">*</span> dw
            self<span class="token punctuation">.</span>b <span class="token operator">-=</span> self<span class="token punctuation">.</span>learn_rate <span class="token operator">*</span> db
            <span class="token comment"># Record the costs</span>
            <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
            <span class="token comment"># Print the cost every 100 training examples</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration %i: %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token punctuation">,</span> cost<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> costs

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)
        :param X_test: input data
        :return: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X_test
        &quot;&quot;&quot;</span>
        m <span class="token operator">=</span> X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        Y_prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">)</span>
        w <span class="token operator">=</span> self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute vector &quot;A&quot; predicting the probabilities</span>
        A <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X_test<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b<span class="token punctuation">)</span>
        <span class="token comment"># Convert probabilities A[0,i] to actual predictions p[0,i]</span>
        Y_prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>A <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>Y_prediction<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> Y_prediction


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    train_size <span class="token operator">=</span> <span class="token number">150</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&quot;iris.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    Y_train <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    Y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> <span class="token string">&quot;Iris-setosa&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    Y_train <span class="token operator">=</span> Y_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> train_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    X_train <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    feature1_min<span class="token punctuation">,</span> feature1_max <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    feature2_min<span class="token punctuation">,</span> feature2_max <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    X_train <span class="token operator">=</span> X_train<span class="token punctuation">.</span>T<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> train_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    clf <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>num_iterations<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>

    <span class="token comment"># 将向量扩充为二维矩阵，作为测试样本</span>
    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>feature1_min<span class="token punctuation">,</span> feature1_max<span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>feature2_min<span class="token punctuation">,</span> feature2_max<span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 预测结果</span>
    Y_prediction <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
    Y_prediction <span class="token operator">=</span> Y_prediction<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># 数据可视化</span>
    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">)</span>
    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">&quot;red&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;blue&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Y_prediction<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">&quot;gray&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>feature1_min<span class="token punctuation">,</span> feature1_max<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>feature2_min<span class="token punctuation">,</span> feature2_max<span class="token punctuation">)</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> y_train <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>Y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> y_train<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> y_train<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> c<span class="token operator">=</span>colors<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span>
                    marker<span class="token operator">=</span>markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>y_train<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">u&quot;花瓣长度&quot;</span><span class="token punctuation">,</span> fontproperties<span class="token operator">=</span><span class="token string">'SimHei'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">u&quot;花茎长度&quot;</span><span class="token punctuation">,</span> fontproperties<span class="token operator">=</span><span class="token string">'SimHei'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">&quot;upper left&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br></div></div></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/suda-morris/blog/edit/master/docs/cs/logistic_regression.md" target="_blank" rel="noopener noreferrer">编辑此页面</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">上次更新: </span> <span class="time">5/8/2019, 7:03:05 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/blog/cs/compilation.html" class="prev">
          编译
        </a></span> <!----></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/blog/assets/js/app.63bb8dec.js" defer></script><script src="/blog/assets/js/2.4a73e09d.js" defer></script><script src="/blog/assets/js/11.72cb3854.js" defer></script><script src="/blog/assets/js/3.b11672f7.js" defer></script>
  </body>
</html>
