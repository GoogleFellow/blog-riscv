(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{252:function(t,a,s){"use strict";s.r(a);var r=s(4),_=Object(r.a)({},function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"q学习——强化学习的具体方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q学习——强化学习的具体方法","aria-hidden":"true"}},[t._v("#")]),t._v(" Q学习——强化学习的具体方法")]),t._v(" "),s("p",[t._v("在Q学习的框架中，作为学习对象的是称为Q值（Q-value）的数值，Q值是指在某种情况下，为了选择下一个要采取的行动的"),s("code",[t._v("指标数值")]),t._v("的集合。根据Q学习而获得Q值，在某个状态下选择下一个行动时，可以根据Q值来进行选择。")]),t._v(" "),s("p",[t._v("Q学习中，获得合适的Q值是学习的目标，在学习的初期，不清楚什么是合适的Q值，所以无法做决定。因此在学习的初期，Q值是由随机数来随机确定的。在此基础上，根据Q值进行行动的选择，更新状态。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://s1.ax1x.com/2018/11/06/iohpUs.jpg",alt:"Q值更新原则1&2"}})]),t._v(" "),s("p",[s("img",{attrs:{src:"https://s1.ax1x.com/2018/11/06/io4rf1.png",alt:"Q值更新原则3"}})]),t._v(" "),s("h2",{attrs:{id:"q值更新的计算公式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q值更新的计算公式","aria-hidden":"true"}},[t._v("#")]),t._v(" Q值更新的计算公式")]),t._v(" "),s("p",[t._v("$$\nQ(s_t,a_t)=Q(s_t,a_t)+\\alpha(r+\\gamma \\space maxQ(s_{t+1},a_{t+1})-Q(s_t,a_t))\n$$")]),t._v(" "),s("ul",[s("li",[t._v("$s_t$表示t时刻的状态，$a_t$表示在$s_t$时所选的行动")]),t._v(" "),s("li",[t._v("$\\max Q(s_{t+1},a_{t+1})$表示在下一个时刻（t+1）能够选择的行动中所对应的Q值中的最大值")]),t._v(" "),s("li",[t._v("$r$表示奖赏（仅限于能够获得时，不能获得的话，是0）")]),t._v(" "),s("li",[t._v("$\\alpha$表示学习系数（0.1左右）")]),t._v(" "),s("li",[t._v("$\\gamma$表示折扣率（0.9左右）")])]),t._v(" "),s("h2",{attrs:{id:"q-learning算法步骤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-learning算法步骤","aria-hidden":"true"}},[t._v("#")]),t._v(" Q-learning算法步骤")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://s1.ax1x.com/2018/11/06/ioXhWD.png",alt:"Q-learning算法步骤"}})])])},[],!1,null,null,null);a.default=_.exports}}]);