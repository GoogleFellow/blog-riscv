(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{217:function(s,t,a){s.exports=a.p+"assets/img/linear_regression.d67e8d49.png"},218:function(s,t,a){s.exports=a.p+"assets/img/nonlinear_regression.f58b96b1.png"},275:function(s,t,a){"use strict";a.r(t);var n=a(4),r=Object(n.a)({},function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("h1",{attrs:{id:"𝙆𝙚𝙧𝙖𝙨-基础"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#𝙆𝙚𝙧𝙖𝙨-基础","aria-hidden":"true"}},[s._v("#")]),s._v(" 𝙆𝙚𝙧𝙖𝙨 基础")]),s._v(" "),n("div",{staticClass:"tip custom-block"},[n("p",{staticClass:"custom-block-title"},[s._v("参考文档")]),s._v(" "),n("p",[n("a",{attrs:{href:"https://keras.io",target:"_blank",rel:"noopener noreferrer"}},[s._v("Keras 官网文档"),n("OutboundLink")],1)])]),s._v(" "),n("h2",{attrs:{id:"安装"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#安装","aria-hidden":"true"}},[s._v("#")]),s._v(" 安装")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 安装 Tensorflow")]),s._v("\npip "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" tensorflow --user -i https://pypi.tuna.tsinghua.edu.cn/simple\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 安装 Keras")]),s._v("\npip "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" keras --user -i https://pypi.tuna.tsinghua.edu.cn/simple\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("h2",{attrs:{id:"线性回归"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#线性回归","aria-hidden":"true"}},[s._v("#")]),s._v(" 线性回归")]),s._v(" "),n("h3",{attrs:{id:"示例程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例程序","aria-hidden":"true"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的顺序模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的全连接层")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造训练样本")]),s._v("\nx_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一维数据，样本量 100，服从均一分布")]),s._v("\nnoise "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 噪声数据，服从高斯分布（正态分布）")]),s._v("\ny_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_train"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" noise\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 1 维， 输入数据 1 维")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sgd"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mse"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：均方差")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" step "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    cost "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train_on_batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" step "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost: "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cost"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看训练得到的权重和偏置")]),s._v("\nw"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_weights"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"W= "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"b= "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 展示拟合结果")]),s._v("\ny_pred "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_pred"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"r-"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lw"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br")])]),n("h3",{attrs:{id:"结果展示"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#结果展示","aria-hidden":"true"}},[s._v("#")]),s._v(" 结果展示")]),s._v(" "),n("p",[n("img",{attrs:{src:a(217),alt:"linear_regression"}})]),s._v(" "),n("h2",{attrs:{id:"非线性回归"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#非线性回归","aria-hidden":"true"}},[s._v("#")]),s._v(" 非线性回归")]),s._v(" "),n("h3",{attrs:{id:"示例程序-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例程序-2","aria-hidden":"true"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的顺序模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Activation  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的全连接层和激活函数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optimizers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" SGD  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的 SGD 优化器")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造训练样本")]),s._v("\nx_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linspace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一维数据，样本量 200，等差线性分布")]),s._v("\nnoise "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.02")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 噪声数据，服从高斯分布（正态分布）")]),s._v("\ny_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("square"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" noise\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 10 维， 输入数据 1 维")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Activation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tanh 激活函数")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 1 维， 输入数据 10 维")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Activation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tanh 激活函数")]),s._v("\nsgd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SGD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置随机梯度下降算法的学习率")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sgd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mse"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：均方差")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" step "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    cost "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train_on_batch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" step "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost: "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cost"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 展示拟合结果")]),s._v("\ny_pred "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_pred"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"r-"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lw"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br")])]),n("h3",{attrs:{id:"结果展示-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#结果展示-2","aria-hidden":"true"}},[s._v("#")]),s._v(" 结果展示")]),s._v(" "),n("p",[n("img",{attrs:{src:a(218),alt:"nonlinear_regression"}})]),s._v(" "),n("h2",{attrs:{id:"mnist-数据分类"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#mnist-数据分类","aria-hidden":"true"}},[s._v("#")]),s._v(" MNIST 数据分类")]),s._v(" "),n("h3",{attrs:{id:"示例程序-3"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例程序-3","aria-hidden":"true"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" mnist\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" np_utils\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Activation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Dropout\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optimizers "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" SGD\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 载入数据集（第一次运行会联网下载）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" mnist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"x_train: "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"y_train: "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"x_test:  "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"y_test:  "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nx_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("255.0")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 归一化")]),s._v("\nx_test "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("255.0")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 标签值转为 one-hot 码")]),s._v("\ny_train "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np_utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_categorical"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ny_test "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np_utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_categorical"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层(隐藏层），输出数据 200 维，输入数据维度由训练数据本身决定, 使用 tanh 激活函数")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dropout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 让 40% 的神经元不工作（防止过拟合的一种手段）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层（隐藏层），输出数据 100 维，输入数据由前一层决定, 使用 tanh 激活函数")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dropout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 让 40% 的神经元不工作（防止过拟合的一种手段）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层（输出层），输出数据 10 维（共 10 种手写数字），输入数据由前一层决定, 使用 softmax 激活函数")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"softmax"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsgd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SGD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置随机梯度下降算法的学习率")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sgd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"categorical_crossentropy"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" metrics"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"accuracy"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：交叉熵")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\nmodel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" epochs"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 评估模型")]),s._v("\nloss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" accuracy "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("evaluate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"loss= "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"accuracy= "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" accuracy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br")])])])},[],!1,null,null,null);t.default=r.exports}}]);